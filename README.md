# 1. About
This is machine learning to categorize image of hand gesture into one of three categories "rock", "paper" or "scissors" based on its form.

# 2. Library and Tools
This app written with Google Collaboratory in Python language. Using Tensorflow version 2.3.0.

# 3. How to use
After download or fork this project, then import MelvinMachineLearningSubmission.ipynb into Google Collaboratory.

You must have account in Google and Google Drive to use Google Collaboratory, then you can access it from https://colab.research.google.com/.

After imported, you can run each cell from top to bottom sequentially, start from import the dataset, split into train and validation, train model until in the end you can upload the picture to test if model run correctly.

# 4. Link
This is link to my drive for access [dataset](https://drive.google.com/drive/folders/1FImC7GpHhILqtFGD8SE_HONk_5bAxObV?usp=sharing)

![Screenshot1](./demo.jpg?raw=true "Rockpaperscissors screenshot")